{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMC4 â€” Hiding `yield` from the Model Specification API\n",
    "\n",
    "Please refer to the `README.org` for context and discussion. In this notebook I will outline my proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run: 2019-07-15 11:51:01.074677\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Last run:\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __future__\n",
    "import ast\n",
    "import functools\n",
    "import inspect\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AST Helper Functions\n",
    "\n",
    "Based on http://code.activestate.com/recipes/578353-code-to-source-and-back/.\n",
    "\n",
    "The main thing to take away from this cell block is that `uncompile` takes a Python object and returns its source code (along with a bunch of other things, but we're less interested in those), and `recompile` takes either:\n",
    "\n",
    "1. the output of `uncompile`, or\n",
    "2. a modified AST, and `compile`s (the Python built-in) it down to bytecode.\n",
    "    \n",
    "The output of `uncompile` can then be `exec`'ed or `eval`'ed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyCF_MASK = sum(v for k, v in vars(__future__).items() if k.startswith(\"CO_FUTURE\"))\n",
    "\n",
    "\n",
    "def uncompile(c):\n",
    "    \"\"\"uncompile(codeobj) -> [source, filename, mode, flags, firstlineno, privateprefix].\"\"\"\n",
    "    if c.co_flags & inspect.CO_NESTED or c.co_freevars:\n",
    "        raise NotImplementedError(\"Nested functions not supported\")\n",
    "    if c.co_name == \"<lambda>\":\n",
    "        raise NotImplementedError(\"Lambda functions not supported\")\n",
    "    if c.co_filename == \"<string>\":\n",
    "        raise NotImplementedError(\"Code without source file not supported\")\n",
    "\n",
    "    filename = inspect.getfile(c)\n",
    "\n",
    "    try:\n",
    "        lines, firstlineno = inspect.getsourcelines(c)\n",
    "    except IOError:\n",
    "        raise RuntimeError(\"Source code not available\")\n",
    "\n",
    "    source = \"\".join(lines)\n",
    "\n",
    "    # __X is mangled to _ClassName__X in methods. Find this prefix:\n",
    "    privateprefix = None\n",
    "    for name in c.co_names:\n",
    "        m = re.match(\"^(_[A-Za-z][A-Za-z0-9_]*)__.*$\", name)\n",
    "        if m:\n",
    "            privateprefix = m.group(1)\n",
    "            break\n",
    "\n",
    "    return [source, filename, \"exec\", c.co_flags & PyCF_MASK, firstlineno, privateprefix]\n",
    "\n",
    "\n",
    "def recompile(source, filename, mode, flags=0, firstlineno=1, privateprefix=None):\n",
    "    \"\"\"Recompile output of uncompile back to a code object. Source may also be preparsed AST.\"\"\"\n",
    "    if isinstance(source, ast.AST):\n",
    "        a = source\n",
    "    else:\n",
    "        a = parse_snippet(source, filename, mode, flags, firstlineno)\n",
    "\n",
    "    node = a.body[0]\n",
    "\n",
    "    if not isinstance(node, ast.FunctionDef):\n",
    "        raise RuntimeError(\"Expecting function AST node\")\n",
    "\n",
    "    c0 = compile(a, filename, mode, flags, True)\n",
    "\n",
    "    return c0\n",
    "\n",
    "\n",
    "def parse_snippet(source, filename, mode, flags, firstlineno, privateprefix_ignored=None):\n",
    "    \"\"\"Like ast.parse, but accepts indented code snippet with a line number offset.\"\"\"\n",
    "    args = filename, mode, flags | ast.PyCF_ONLY_AST, True\n",
    "    prefix = \"\\n\"\n",
    "    try:\n",
    "        a = compile(prefix + source, *args)\n",
    "    except IndentationError:\n",
    "        # Already indented? Wrap with dummy compound statement\n",
    "        prefix = \"with 0:\\n\"\n",
    "        a = compile(prefix + source, *args)\n",
    "        # Peel wrapper\n",
    "        a.body = a.body[0].body\n",
    "    ast.increment_lineno(a, firstlineno - 2)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC4 Backend\n",
    "\n",
    "Now, let's talk about what the backends need to look like.\n",
    "\n",
    "First, a helper class to traverse and transform the AST of the user-defined model specification function. Half the magic is in this class: please read the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionToGenerator(ast.NodeTransformer):\n",
    "    \"\"\"\n",
    "    This subclass traverses the AST of the user-written, decorated,\n",
    "    model specification and transforms it into a generator for the\n",
    "    model. Subclassing in this way is the idiomatic way to transform\n",
    "    an AST.\n",
    "\n",
    "    Specifically:\n",
    "    \n",
    "    1. Add `yield` or `yield from` keywords to distribution assignments\n",
    "       E.g. `x = tfd.Normal(0, 1)` -> `x = yield tfd.Normal(0, 1)`\n",
    "    2. Rename the model specification function to `_model_generator`.\n",
    "    3. Remove the @Model decorator. Otherwise, we risk running into\n",
    "       an infinite recursion.\n",
    "    \"\"\"\n",
    "    def visit_Assign(self, node):\n",
    "        # If the assigned value is not a function call, return the original node\n",
    "        # I.e., do nothing to assignments like `N = 10`, `mu = x.mean`,\n",
    "        # or even `x = yield tfd.Normal(0, 1)`\n",
    "        if not isinstance(node.value, ast.Call):\n",
    "            print(\"Skipping {}\".format(node.value))\n",
    "            return node\n",
    "                \n",
    "        # The function that is being called. E.g. `tfd.Normal`\n",
    "        function = node.value.func\n",
    "        \n",
    "        if isinstance(function, ast.Name):\n",
    "            # `function` is a user-defined function in the global namespace (e.g. \"Horseshoe()\")\n",
    "            function_name = function.id\n",
    "            assigned_value = globals()[function_name]\n",
    "        elif isinstance(function, ast.Attribute):\n",
    "            # `function` is a module function (e.g. `tfd.Normal()`)\n",
    "            # Unroll _all_ levels of ast.Attributes... (E.g. `tfd.distributions.Normal()`)\n",
    "            names = []\n",
    "            while isinstance(function, ast.Attribute):\n",
    "                names.append(function.attr)\n",
    "                function = function.value\n",
    "            else:\n",
    "                module_name = function.id\n",
    "                names.reverse()\n",
    "            assigned_value = globals()[module_name]\n",
    "            for name in names:\n",
    "                assigned_value = getattr(assigned_value, name)\n",
    "        else:\n",
    "            # If it is not something we expect, it is better to fail fast than continue silently.\n",
    "            msg = \"Model contains assignment of {}. Expected assignments of ast.Names or ast.Attributes\".format(type(function))\n",
    "            raise RuntimeError(msg)\n",
    "            \n",
    "        if isinstance(assigned_value, tfd.distribution._DistributionMeta):\n",
    "            # Add a `yield`\n",
    "            print(\"Adding `yield` to {}\".format(assigned_value))\n",
    "            new_node = node\n",
    "            new_node.value = ast.Yield(value=new_node.value)\n",
    "        elif isinstance(assigned_value, Model):\n",
    "            # Add a `yield from`, and call the model_generator, not the model itself\n",
    "            print(\"Adding `yield from` to {}\".format(assigned_value))\n",
    "            new_node = node\n",
    "            new_node.value = ast.YieldFrom(value=new_node.value)\n",
    "            new_node.value.value.func = ast.Attribute(\n",
    "                value=ast.Name(id=new_node.value.value.func.id, ctx=ast.Load()),\n",
    "                attr=\"model_generator\",\n",
    "                ctx=ast.Load())\n",
    "        else:\n",
    "            # Must be some other function, like `tf.zeros()` or something\n",
    "            print(\"Skipping {}\".format(assigned_value))\n",
    "            return node\n",
    "\n",
    "        # Fix location (line numbers and column offsets) of replaced node.\n",
    "        # Recursively visit child nodes.\n",
    "        ast.copy_location(new_node, node)\n",
    "        ast.fix_missing_locations(new_node)\n",
    "        self.generic_visit(node)\n",
    "        return new_node\n",
    "    \n",
    "    # TODO: edge case of augmented and type-annotated assignments.\n",
    "    # visit_AugAssign = visit_Assign\n",
    "    # visit_AnnAssign = visit_Assign\n",
    "    \n",
    "    def visit_FunctionDef(self, node):\n",
    "        new_node = node\n",
    "        new_node.name = \"_model_generator\"\n",
    "        new_node.decorator_list = []\n",
    "\n",
    "        # Fix location (line numbers and column offsets) of replaced node.\n",
    "        # Also recursively visit child nodes.\n",
    "        ast.copy_location(new_node, node)\n",
    "        ast.fix_missing_locations(new_node)\n",
    "        self.generic_visit(node)\n",
    "        return new_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the `pm.Model` decorator. Instead of a function, our decorator [will be a class](https://realpython.com/primer-on-python-decorators/#classes-as-decorators). This allows us to have a stateful decorator, where we can store model-related things (e.g. the AST and the generator) and even define user-facing functions such as `sample` or `observe`. The other half of the magic is in this class: please read the comments and docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\" Model decorator. \"\"\"\n",
    "\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "        # Introspect wrapped function, instead of the decorator class.\n",
    "        functools.update_wrapper(self, func)\n",
    "\n",
    "        # Uncompile wrapped function\n",
    "        uncompiled = uncompile(func.__code__)\n",
    "\n",
    "        # Parse AST and modify it\n",
    "        tree = parse_snippet(*uncompiled)\n",
    "        tree = FunctionToGenerator().visit(tree)\n",
    "        uncompiled[0] = tree\n",
    "        \n",
    "        # Convert modified AST to readable Python source code.\n",
    "        # FIXME: needs to be in a file!!\n",
    "        # source = astor.to_source(tree)\n",
    "        # uncompiled[1] = source\n",
    "\n",
    "        # Recompile wrapped function\n",
    "        self.recompiled = recompile(*uncompiled)\n",
    "        \n",
    "        # Execute recompiled code (defines `_model_generator`) in the\n",
    "        # locals() namespace and assign it to an attribute. Refer to\n",
    "        # http://lucumr.pocoo.org/2011/2/1/exec-in-python/\n",
    "        exec(self.recompiled, None, locals())\n",
    "        self.model_generator = locals()[\"_model_generator\"]\n",
    "\n",
    "    \"\"\"\n",
    "    The following three functions aren't necessary for the rest of the notebook.\n",
    "    I just want to point out that this would be natural places to define these functions.\n",
    "    Refer to the \"User-Facing API\" section (below) for why.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    \n",
    "    def sample(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"George isn't sure how sampling works.\")\n",
    "\n",
    "    def observe(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"George isn't sure how observing works, either.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Facing Model Specification API\n",
    "\n",
    "And now all users need to see is this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-function models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.half_cauchy.HalfCauchy'>\n",
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.normal.Normal'>\n",
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.normal.Normal'>\n"
     ]
    }
   ],
   "source": [
    "@Model\n",
    "def linear_regression(x):\n",
    "    scale = tfd.HalfCauchy(0, 1, name=\"scale\")\n",
    "    coefs = tfd.Normal(tf.zeros(x.shape[1]), 1, name=\"coefs\")\n",
    "    predictions = tfd.Normal(tf.linalg.matvec(x, coefs), scale, name=\"predictions\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.gaussian_process.GaussianProcess'>\n"
     ]
    }
   ],
   "source": [
    "@Model\n",
    "def gaussian_process():\n",
    "    # Works with \"nested\" distributions too... E.g. `tfd.foo.Distribution()`\n",
    "    gaussian_process = tfd.gaussian_process.GaussianProcess(kernel=tf.identity(3))\n",
    "    return gaussian_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping <_ast.Yield object at 0x126bbcbe0>\n",
      "Skipping <_ast.Yield object at 0x126bbcb00>\n",
      "Skipping <_ast.Yield object at 0x126bdf198>\n"
     ]
    }
   ],
   "source": [
    "@Model\n",
    "def linear_regression_with_yields(x):\n",
    "    # Even works with users who _prefer_ to write `yield`...\n",
    "    # (Notice how it prints nothing!)\n",
    "    scale = yield tfd.HalfCauchy(0, 1, name=\"scale\")\n",
    "    coefs = yield tfd.Normal(tf.zeros(x.shape[1]), 1, name=\"coefs\")\n",
    "    predictions = yield tfd.Normal(tf.linalg.matvec(x, coefs), scale, name=\"predictions\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-function (\"nested\") models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.half_cauchy.HalfCauchy'>\n",
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.normal.Normal'>\n",
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.half_cauchy.HalfCauchy'>\n",
      "Adding `yield from` to <__main__.Model object at 0x126bdf358>\n",
      "Adding `yield` to <class 'tensorflow_probability.python.distributions.normal.Normal'>\n"
     ]
    }
   ],
   "source": [
    "# From https://gist.github.com/ferrine/59a63c738e03911eacba515b5be904ad\n",
    "@Model\n",
    "def Horseshoe(mu=0., tau=1., s=1., name=\"horseshoe_scope\"):\n",
    "    with tf.name_scope(name):\n",
    "        scale = tfd.HalfCauchy(0, s, name=\"scale\")\n",
    "        noise = tfd.Normal(0, tau, name=\"noise\")\n",
    "        return scale * noise + mu\n",
    "\n",
    "@Model\n",
    "def regularized_linear_regression(x):\n",
    "    scale = tfd.HalfCauchy(0, 1, name=\"scale\")\n",
    "    coefs = Horseshoe(tf.zeros(x.shape[1]), name=\"coefs\")\n",
    "    predictions = tfd.Normal(tf.linalg.matvec(x, coefs), scale, name=\"predictions\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What else can we do in the `Model` decorator?\n",
    "\n",
    "1. If we define `__call__`, then users can run `predictions = linear_regression(tf.zeros([3, 10]))`. I am unsure what we would want this to return. Note that this will **not** be as straightfoward as\n",
    "\n",
    "    ```python\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    ```\n",
    "   since (currently) `self.func` is the user-defined function that crashes (just as in @ferrine's example). More bluntly, users will be writing a function that, without the `@Model` decorator, crashes. On the other hand, if we _don't_ implement `__call__`, users will write a function and get back a `Model` object that _cannot be called_, as you would expect a function to be. Tricky situation; food for thought; feedback needed!\n",
    "\n",
    "2. If we define `sample`, then users can sample from their model via `linear_regression.sample()`.\n",
    "\n",
    "3. If we define `observe`, then users can provide observations to their model via `linear_regression.observe()` (as suggested by @ferrine and @rpgoldman)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three statements will raise NotImplementedErrors.\n",
    "\n",
    "'''\n",
    "predictions = linear_regression(tf.zeros([3, 10]))\n",
    "linear_regression.sample()\n",
    "linear_regression.observe()\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC4 Core Engine\n",
    "\n",
    "We can get the generator in exactly the same way that @ferrine's notebook requires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _model_generator at 0x10baa8990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.model_generator(tf.zeros([3, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _model_generator at 0x126ba7830>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularized_linear_regression.model_generator(tf.zeros([3, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!!\n",
    "\n",
    "In fact, to demonstrate that it's actually the generator we need (and that there aren't subtle bugs along the way), we can interact with the generator in exactly the same way as in @ferrine's notebook.\n",
    "\n",
    "I've omitted the \"One level deeper\" section in the notebook: that is, recursively interacting with the generator. I haven't tested it out, but I expect that it would also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://gist.github.com/ferrine/59a63c738e03911eacba515b5be904ad\n",
    "\n",
    "def interact(gen, state):\n",
    "    control_flow = gen()\n",
    "    return_value = None\n",
    "    while True:\n",
    "        try:\n",
    "            dist = control_flow.send(return_value)\n",
    "            if dist.name in state[\"dists\"]:\n",
    "                control_flow.throw(RuntimeError(\n",
    "                    \"We found duplicate names in your cool model: {}, \"\n",
    "                    \"so far we have other variables in the model, {}\".format(\n",
    "                        preds_dist.name, set(state[\"dists\"].keys()), \n",
    "                    )\n",
    "                ))\n",
    "            if dist.name in state[\"samples\"]:\n",
    "                return_value = state[\"samples\"][dist.name]\n",
    "            else:\n",
    "                return_value = dist.sample()\n",
    "                state[\"samples\"][dist.name] = return_value\n",
    "            state[\"dists\"][dist.name] = dist\n",
    "        except StopIteration as e:\n",
    "            if e.args:\n",
    "                return_value = e.args[0]\n",
    "            else:\n",
    "                return_value = None\n",
    "            break\n",
    "    return return_value, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-function models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, state = interact(lambda: linear_regression.model_generator(tf.zeros([3, 10])),\n",
    "                        state=dict(dists=dict(), samples=dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([174.78996   20.97928   47.357864], shape=(3,), dtype=float32)\n",
      "\n",
      "{'dists': {'scale': <tfp.distributions.HalfCauchy 'scale' batch_shape=[] event_shape=[] dtype=float32>, 'coefs': <tfp.distributions.Normal 'coefs' batch_shape=[10] event_shape=[] dtype=float32>, 'predictions': <tfp.distributions.Normal 'predictions' batch_shape=[3] event_shape=[] dtype=float32>}, 'samples': {'scale': <tf.Tensor: id=37, shape=(), dtype=float32, numpy=108.2138>, 'coefs': <tf.Tensor: id=65, shape=(10,), dtype=float32, numpy=\n",
      "array([ 1.3074126 ,  2.6881516 ,  0.06404222, -0.16281821, -0.58692205,\n",
      "        1.5679766 , -0.5559973 ,  0.8432684 , -0.21408895,  1.4693985 ],\n",
      "      dtype=float32)>, 'predictions': <tf.Tensor: id=93, shape=(3,), dtype=float32, numpy=array([174.78996 ,  20.97928 ,  47.357864], dtype=float32)>}}\n"
     ]
    }
   ],
   "source": [
    "print(preds, state, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-function (\"nested\") models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, state = interact(lambda: regularized_linear_regression.model_generator(tf.random.normal([3, 10])),\n",
    "                        state=dict(dists=dict(), samples={\"predictions/\": tf.zeros(3)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 60.178547    1.9002857 -78.334015 ], shape=(3,), dtype=float32)\n",
      "\n",
      "{'dists': {'scale': <tfp.distributions.HalfCauchy 'scale' batch_shape=[] event_shape=[] dtype=float32>, 'coefs_scale': <tfp.distributions.HalfCauchy 'coefs_scale' batch_shape=[] event_shape=[] dtype=float32>, 'coefs_noise': <tfp.distributions.Normal 'coefs_noise' batch_shape=[] event_shape=[] dtype=float32>, 'predictions': <tfp.distributions.Normal 'predictions' batch_shape=[3] event_shape=[] dtype=float32>}, 'samples': {'predictions/': <tf.Tensor: id=101, shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, 'scale': <tf.Tensor: id=136, shape=(), dtype=float32, numpy=0.8348854>, 'coefs_scale': <tf.Tensor: id=169, shape=(), dtype=float32, numpy=15.626522>, 'coefs_noise': <tf.Tensor: id=195, shape=(), dtype=float32, numpy=1.3660036>, 'predictions': <tf.Tensor: id=225, shape=(3,), dtype=float32, numpy=array([ 60.178547 ,   1.9002857, -78.334015 ], dtype=float32)>}}\n"
     ]
    }
   ],
   "source": [
    "print(preds, state, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Next Steps\n",
    "\n",
    "Please refer to the `README.org`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.7 :: Anaconda, Inc.\n",
      "jupyter==1.0.0\n",
      "tensorflow==2.0.0-beta1\n",
      "tfp-nightly\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
